----------------------------------------------------------------------------------------------------------------------------------------------------------------------

TEXTURES (FINISHED)
. Show developed examples
	. Standard texture mapping
		. In this video I'm going to explain how to use textures in DirectX 12 and show different examples of it's use, this is an standard use of textures
	. Tiled texture mapping
		. Here we have a tiled texture, where we repeat this texture, this could be useful for using only 1 texture on big objects
		  like a wall of bricks or a terrain 
	. Shader using multiple textures 
		. We can also use different textures on the same shader and animate them to achieve an effect like this fireball

. Walkthrough on the C++ code
	. (Line 180)First thing that we need to do is load the textures that we are going to use on the initialize method of the app
	. (Line 450)In this case we are going to use the CreateDDSTextureFromFile12 method from Frank Luna's samples
	. This function will need a pointer to the device, a pointer to the command list, the filename of the texture,
	  and also the texture resource and the uploadHeap to fill them internally. If we aren't using that function, we will need 
	  to create a resource descriptor with the texture parameters, create a committed resource for the texture and a commited resource
	  for the texture upload heap, in this case all of that things will be done internally with this method
	. (Line 462) Now we need to create the root signature for the shader that we are going to use
	. We create a descriptor range and initialize with the DESCRIPTOR_RANGE_TYPE_SRV, the number of textures on this table
	  and the base shader register where is going to be set
	. (Line 471) Then we initialize the descriptor table with the number of descriptor ranges, the table itself and the shader visibility
	. And we inilitalize the other root parameters that the shader needs
	. Next thing that we need is the sampler or samplers for the textures
	. (Line 697)We can create an array of them to use different ones in a shader
	. Those samplers will indicate the way that the texture should behave with
	  magnifcation, minification and the adress mode on its coordinates
	. (Line 491) Back in the creation of the root signature, we get those samplers and we create a root Signature descriptor, filling
	  it with the number of parameters, the parameters, the size of samplers, the samplers and the flags
	. Then we serialize it and create it to use it later (stored on m_rootSignature)
	. (Line 502) Now we need to build the descriptor heaps for the textures
	. So we create a descriptor heap description, fill it with the needed parameters and call the CreateDEscriptorHeap method
	. (Line 516) We have to create a CPU_DESCRIPTOR_HANDLE also, and we do it like this
	. (Line 520-526) Then, for each texture on the descriptor heap we need to create a Shader Resource View, so we have to fill a 
	  Shader Resource View Description with these parameters
	. And we call the CreateShaderResourceView method with the texture resource, the shader resource viewdescription and the cpu
	  descriptor handle for each texture
	. (Line 540) One of the most important things for using textures, is to have the model uvs, so we need to add them on the input layout of the shaders
	. So when we create a geometry or load a model we need to store these values on the Vertex structure and upload them to the vertex buffer	
	. (Line 261) Finally, In the draw method we need to set the descriptor heaps for the textures, so we get them and call the SetDescriptorHeaps method
	. In the draw render items method, we need to set the current texture for each item, so we could use the same shader with different textures by object
	. (Line 683) So we get the gpu descriptor handle of the texture 
	. (Line 689) and set it for the shader calling the SetGraphicsRootDescriptorTable with the index of the root parameter and the gpu descriptor handle
	
	. As an extra appointment, if we need to use multiple textures on a shader, we can use a texture array
	. (Put the line) So we can modify the texture shader resource view with more than one texture
	. (Put the line) And creating the descriptr heap we can use a loop changing the current texture and using the Offset method to set them 

. Process to use a texture on HLSL
	. The last step is to use it on the shader calling the texture function 'Sample', with the g_sampler and model uvs.
		. This will return a vector of 4 components, that in this case are going to be the rgba channels
	. Show texture tiling functionality
		. We can tile a texture by multipliying its uvs
	. Show shader using multiple textures (Texture blending)
		. We can transform the object uvs like any other point with a 2d matrix
		. And combining them adding, substracting or multiplying its components like in this case


----------------------------------------------------------------------------------------------------------------------------------------------------------------------

BLENDING (FINISHED)
. Show developed examples
	. Transparency
		. In this video we are going to show some blending techniques, such as the transparency shown in this water, where we are	
		drawing a percentage of the water color over the grass color. This is useful for objects like water or glass
	. Alpha testing (clipping)
		. Other technique is the alpha testing that, which we can see in this box, where we are rendering only the pixels that 
		are visible and discarding the render of the ones that are not opaque, this is useful for objects like fences
	. Fog
		. And the fog technique, where we blend the original color of the pixels with the fog color based on the distance to the 
		camera, where we have a point in the distance where the fog starts, and the intensity of the fog increases with the 
		distance until the color is completely the color of the fog. We can use this effect to hide popping errors or to simulate
		weather effects

. Walktrough on the code
	. By blending objects we can combine the color of the source pixels, which are the ones we are rasterizing currently,
	  with previous rendered ones, which are the destination pixels
	. In order to do this, we need to create different PSOs to change the pipeline state depending on the object that we are going to draw
	. (Line 840) First we create the opaque one, that is the standard one to draw opaque objects.
	. (Line 870) Then we create the transparent PSO, where we have to set all the parameters needed for the blending.
	. The RGB and alpha channels are blended separetely,
	. (Line 874) such as enable the blending
	. (Line 876 - 877) set the blend factors for source and destination pixels
	. (Line 878) and set the blend operation
	. (Line 879 - 881) and the same for the alpha components
	. Finally, we create another PSO for the alpha tested objects.
	. (Line 892) that is the same as the opaque PSO, because with this state we render a pixel as opaque or we discard it directly
	. (Line 898) the only thing that we need to change is rasterizer state cull mode to none
	. (Line 291) Finally, we need to order the objects and render the opaque ones first, then alpha tested and then render transparent 
	objects from back to front
	. To do this, we can change the PSOs as needed with SetPipelineState method

. Walktrough on the shader
	. Alpha is interpreted as a percentage of the color, so in the case of the water material whare alpha has been set to 0.5, 
	the result will be that we draw a 50% of the water color in the destination pixel
	. Clip function discard pixels from being processed, and this doesnt require the objects to be sort as they are interpreted to be opaque
	  , this function can only be called on pixel shader
	. (Shader 61 - 63)To use the fog, we will need some parameters, which they are these ones 
	. The fog color will determine the color of the fog
	. The fog start will determine at which distance the fog will start to blend with the destination pixels
	. And the fog range will determine the increase of the fog blending until it reach a distance where the color is 100% the color of the fog
	. (Shader 150) Then, if fog is enabled, we compute the value of the fog from 0 to 1, using the fog parameters
	. We compute the distance of the current rendering pixel to the position of the camera to substract the fog start value to it,
	so we start the fog from an specific distance, then we divide it by the fog range value
	. The saturate function will clamp the value from 0 to 1 to use later on the lerp function, mixing the original color with the 
	computed fog amount.

----------------------------------------------------------------------------------------------------------------------------------------------------------------------

STENCILING (FINISHED)
. Show developed examples and technique explanation ???
	. Planar reflections
		. In this video we are going to talk about some stenciling techniques, such as planar reflections, that are the ones that
		we can see on  a mirror like this one, or in a plane floor made of marble or some other material with reflections.

		. To allow this to work we will need to render the reflected geometries that we want to reflect in the mirror, the skull in
		this case, and the same with the light source, and then we will need to draw in the stencil buffer the mirror surface, 
		so the reflected skull will only be drawn where the stencil buffer has an specific value.
		. If we aren't using the stencil buffer, we will have an error like this (show skull behind the wall)
	. Planar shadows
		. Other technique that we can show that uses stenciling are planar shadows like this one, allowing us to correctly project 
		the shadow of an object in a plane surface.

		. The stencil buffer is not used to actually cast the shadow, this is another topic that is covered using geometric approaches
		such as shadow matrixes, that projects the current 3d geometry triangles in to a flattened 2d surface. Although, some of that 
		projected triangles will be overlapping and some shadow areas will be darker than others, so to prevent that error called 
		'double blending', we use the stencil buffer to set the areas that has been currently rendered unable to render again, so
		the complete surface of the shadow will be of the same colour.
		. If we aren't using the stencil buffer, we will have an error like this (show 'double blending' error)

. Walktrough on the planar mirror code
	. (Line 188) The stencil buffer is created at the same time that the depth buffer when we call the D3DApp::Initialize
	. When we call this function the default value of both buffers is set to 0 and the format of both is set too
	. To use the planar mirror technique, we are going to need different PSOs for different purposes
	. (Line 953) After creating the standard opaque and transparent PSOs that we will also use, we need to create a PSO to draw the mirror
	only in the stencil buffer, so we do it in the following way
	. (Line 956) We create a blend state with the default values and set the rendertargetwritemask to 0
	. (Line 959) Then we create a depth stencil descriptor, we set the depth settings and we eneable the stencil
	and set the stencilreadmask and the stencilwritemask
	. (Line 967) Now we need to fill the front face settings for the stencil
	. So if the stencil or the depth fails, we keep the current value of the stencil
	. But if the stencil passes, we replace the current value with the new one
	. And we set always on the stencil function because we always want to compute the stencil test for this PSO
	. (Line 973) As we are not going to render backfaces, those settings doesnt matter
	. So we copy the opaque PSO descriptor on this new one, and set the blend state and the depth stencil state that
	we have just created
	. (Line 987) Now we have to create another PSO for the reflected objetcs, this will have the same settings except that
	the depth write mask will be all instead of zero, the stencil pass for the front face will be keep, and the
	comparison function will be equal instead of always, with these settings the reflected objects will only be drawn 
	where the mirror has modified the value of the stencil
	. (Line 1008) With these settings, the triangles of the reflected object will be culled on the wrong way, so we have
	to change the cull mode of the rasterizer to BACK and set the frontcounterclockwise to true
	. (Line 127) We will also need to store an independent render item for the reflected skull, as it needs a different world matrix
	. (Line 414) We store it when we create the render items and later on the update we calculate its new world matrix by multipliying
	the normal skull world matrix with the reflected mirror matrix
	. (Line 537) And the last thing that we need is another cbv for the reflected objects with inverse lighting, so we get the main cbv
	and multiply the light direction with the reflected mirror matrix and store them on thew reflected cbv

	. (Line 255) Now that we have all the neccesary things, we need to take a look on the draw method
	. (Line 276) Here we need to reset the stencil buffer at the beginning of each frame, like the depth, so we do it at the same 
	time using the ClearDepthStencilView method and setting the flags to do it, and the values that we want to set, that are 0 for both
	. (Line 288) Then we draw the opaque render items as always with the opaque PSO, so if any of these objects occludes a part of the 
	mirror it won't be marked later on the stencil
	. (Line 294) Now we are going to draw the visible mirror areas on the stencil, so we set the stencil reference value to 1 with the
	OMSetStencilRef	method, then we change the pipeline state to the mark stencil mirror PSO that we have created before and draw the mirror
	. (Line 300) After that, we are going to draw the actual reflected objects, so we have to switch the main cbv with the reflected one
	to draw the objects with the inverted lights, we set the pipeline state to the draw stencil reflections and render the reflected items,
	as we have set this PSO, the reflected objects will only be drawn where the stencil value is equal to 1
	. (Line 305) The last step is to restore the stencil ref to 0 and set again the main pass cbv as we have finished the reflected drawing
	. (Line 309) And finally we render the mirror with transparency to keep a percentage of the mirror color and the rest of the reflected skull

. Walktrough on planar shadows
	. The steps for the planar shadows are pretty much the same
	. (Line  1013) First we need to create another PSO for the shadow object
	. This one is exactly the same as the mirror stencil one, except that we need to set the stencil pass operation as Increase instead of replace
	. With this operation, we will increase the value from 0 to 1, but if it is already one, the stencil test will fail and will leave a 1
	in the stencil buffer, so with this we will prevent to draw multiple times on the same pixel and we will get rid of the 'double blending'
	error
	. (Line 419) Now that we have the PSO, as in the planar mirror example, we need to calculate the world matrix for the shadow object, 
	so we get the normal skull world matrix and then we multiply it by a computed shadow matrix with the light direction and the shadow plane
	. (Line 313) The final step is to draw the skull shadow with the shadows PSO, so with the stencil that we have set, no 'double
	blending' effect will appear. 

----------------------------------------------------------------------------------------------------------------------------------------------------------------------
